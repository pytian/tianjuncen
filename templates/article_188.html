<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title></title>
</head>
<body><!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="../static/css/bootstrap.min.css">

    <title>强化学习是什么？</title>
    <style>
        ul {
            list-style-type: none;
        }

        li {
            float: left;
            margin: 20px;
        }

        .row {
            border: rgba(0,0,0,0.3) 1px solid;
            margin: 10px;
        }
    </style>
</head>
<body>
<div class="container">
    <div class="row">
        <div class="col-md-12">
            <p>
                强化学习是什么？
            </p>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <p>
                <!-- wp:paragraph -->
<p>强化学习是一种试错方法，其目标是让软件智能体在特定环境中能够采取回报最大化的行为。强化学习在马尔可夫决策过程环境中主要使用的技术是动态规划（Dynamic Programming）。流行的强化学习方法包括自适应动态规划（ADP）、时间差分（TD）学习、状态-动作-回报-状态-动作（SARSA）算法、Q 学习、深度强化学习（DQN）；其应用包括下棋类游戏、机器人控制和工作调度等。</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>过去的2018年在框架空间中取得很多有趣进展的另一个领域是强化学习。虽然我觉得 RL 研究进展不像前几年那样令人印象深刻（只能想起来 DeepMind 的近期研究 <a rel="noreferrer noopener" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650737603&amp;idx=4&amp;sn=216d3980555ab9e6e8365b6e2f83cad4&amp;chksm=871acfbdb06d46abe8c47f0cb2b7190e765d66fb0104e0beeafd1db156b2a36ac3698409b46d&amp;scene=21#wechat_redirect" target="_blank">IMPALA</a>），但在仅仅一年的时间里看到所有主流 AI 玩家发布 RL 框架还是非常惊喜的。谷歌发布了 <a rel="noreferrer noopener" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650747638&amp;idx=2&amp;sn=14ad429dabc0f45cb46faf83329a3e07&amp;chksm=871af688b06d7f9ef71a9cf5d4a186b294ff01374bc3ef70a18ad0ad4bf62c5b925fc2c03691&amp;scene=21#wechat_redirect" target="_blank">Dopamine</a> 研究框架，Deepmind 发布了颇有竞争力的 TRFL 框架。Facebook 不甘落后，发布了 <a rel="noreferrer noopener" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650751149&amp;idx=3&amp;sn=88e1f34fde6c759f2c0432201a479731&amp;chksm=871a84d3b06d0dc508bd1aa8f9d5142bb849f9e9f40bf8a0efc4403b1c675e51f5c298b5e591&amp;scene=21#wechat_redirect" target="_blank">Horizon</a>，微软也发布了专门用于训练基于文本的智能体的 TextWorld。希望这些开源福利可以帮助我们在 2019 年取得更多 RL 进展。</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>谷歌最近发布了基于&nbsp;TensorFlow&nbsp;的 TFRank。排序是 ML 应用中极其重要的一个应用方向，应该得到更多应有的重视。</p>
<!-- /wp:paragraph -->
            </p>
        </div>
    </div>
</div>

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
        integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
        crossorigin="anonymous"></script>
<script src="../static/js/bootstrap.min.js"></script>
</body>
</html>