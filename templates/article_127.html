<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title></title>
</head>
<body><!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="../static/css/bootstrap.min.css">

    <title>阿里iDST SLQA 技术是怎么实现对内容的理解的？</title>
    <style>
        ul {
            list-style-type: none;
        }

        li {
            float: left;
            margin: 20px;
        }

        .row {
            border: rgba(0,0,0,0.3) 1px solid;
            margin: 10px;
        }
    </style>
</head>
<body>
<div class="container">
    <div class="row">
        <div class="col-md-12">
            <p>
                阿里iDST SLQA 技术是怎么实现对内容的理解的？
            </p>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <p>
                本次阿里巴巴参与测评的系统名为 SLQA，即 SLQA，即 Semantic Learning for Question Answering，是 iDST NLP 团队提出的「基于分层融合注意力机制」的深度神经网络系统。评测证明，相比传统方法，SLQA 的效果取得了显著的提升。

采用传统方法解决机器阅读理解问题，一般会将该过程分为以下几个步骤：1）对问题、篇章分别进行词法、句法分析，针对分析结果进行特征提取：2）基于特征采用诸如 LR、CRF 等模型进行答案边界预测；
3）采用梯度下降类算法在训练集上进行优化，拟合数据分布。

在此过程中，基础语言模型、依存分析等模块的准确率在一定程度上会影响训练效果，特征工程的优劣也同样左右着是否能训练得到可用的模型。随着深度学习在 NLP 领域的大量应用，很多场景如切词、词性标注、翻译、命名实体识别等 End2End 模型逐渐取得接近并超越传统模型的效果。在机器阅读理解场景，iDST NLP 团队设计了 Semantic Learning Net，即 SLQA 背后的算法模型。该模型模拟人类在做阅读理解问题时的一些行为，包括结合篇章内容审题、带着问题反复阅读文章、避免阅读中遗忘而进行相关标注等。

<img class="alignnone size-medium wp-image-128" src="https://yuedusikao.com/wordpress/wp-content/uploads/2018/12/阿里机器理解的idst架构-279x300.png" alt="" width="279" height="300" />

iDST团队总结，人类在进行阅读理解时，常见思维顺序如下：

1）通读篇章，理解文章主题和大体内容；读题，了解提问内容及关注点。

2）带着问题找答案，将问题同篇章做关联，并结合篇章主题，理解问题重点。

3）定位可能的答案范围，并再次重点阅读附近文字。

4）为避免忘记问题，再次审题，并结合

3）中重点区域进行答案圈选。

5）针对挑出的答案候选进行精筛，确定最正确的答案。

结合以上思路，团队构建模型的主要思想是在捕捉问题和文章中特定区域关联的同时，借助分层策略，逐步集中注意力，使答案边界清晰。同时，为了避免过于关注细节，团队采用融合方式将全局信息加入注意力机制，进行适度纠正，确保关注点正确。

这种逐步聚焦并兼顾全局的方式与其他参赛者已经公布的的做法不太相同，也是团队此次刷榜登顶的关键所在。目前业界主流的基于 End2End 学习的机器阅读理解模型主要为 Encode-Interaction-Pointer 框架。基于上述分析，SLQA 系统包含如下基本结构：Encoder Layer（文本表征），Attention Layer（注意力机制），Match Layer（问题篇章匹配）以及 Output Layer（答案预测）。Encoder Layer 用于表示学习，可以理解为语言模型层，用以将篇章及问题从离散字符转变为蕴含语义的表征向量。团队采用了多层双向 LSTM 并分别对篇章和问题进行主题和重点词关注。Attention Layer 得到有效的问题及篇章表征后，为表达依据问题定位答案过程，缩小备选答案查找范围，将搜索空间通过注意力机制约束，主要进行多层融合注意力表示，对问题和篇章进行相关性对齐（Align），并不断补充全局信息（Fusion），每一次对齐都基于下层信息并在此基础上更加细化（paragraph→sentence→phrase→word），采用的方式分别为 Co-Attention（篇章到问题，问题到篇章），Self-Attention（问题自身，篇章自身）。Match Layer 用于做融合信息后的问题和篇章匹配，团队采用双线性矩阵来学习经过多层信息过滤后的篇章和问题匹配参数，由于在前一阶段无关信息已经被过滤，最后的匹配可完成答案的定位工作。Output Layer 结合匹配信息对篇章中词汇进行标注，预测相应词汇是答案开始位置或结束位置的概率。之后，模型会抽取可能性最高的一段连续文本作为答案。团队采用的技术就是基于以上四个Layer的深度神经网络模型，重点探索和研究的Layer是第三层（Hierarchical Attention Fusion Network）。

iDST NLP 团队负责人司罗表示，本次 SQuAD 评测登顶得益于其 NLP 团队自身的完善性。「NLP 领域内的很多技术方向可以互相借鉴，例如机器阅读理解任务，我们就借鉴了机器翻译的一些技术。应该说我们机器阅读理解的技术是建立在我们更广阔的自然语言处理能力上的。」

来源： <em><a href="https://www.jiqizhixin.com/articles/2018-01-14-4">机器阅读理解打破人类记录，解读阿里iDST SLQA 技术 | 机器之心</a></em>
            </p>
        </div>
    </div>
</div>

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
        integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
        crossorigin="anonymous"></script>
<script src="../static/js/bootstrap.min.js"></script>
</body>
</html>